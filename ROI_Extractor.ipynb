{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os \n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import rembg \n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"PlantClassificationModels/KERAS MODELS/MRV_VGG.keras\")\n",
    "\n",
    "with open(\"PlantClassificationModels/LabelEncoderData.pkl\", \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GET_ROI_TRANSFORMATIONS = False\n",
    "ROI_CW = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(joined_path):\n",
    "    im = cv2.imread(joined_path, cv2.IMREAD_ANYCOLOR)\n",
    "    return im\n",
    "\n",
    "def get_dimensions(im):\n",
    "    w, h = im.shape[:2]\n",
    "    w_steps = w // ROI_CW\n",
    "    h_steps = h // ROI_CW\n",
    "    w_residual = w - w_steps * ROI_CW\n",
    "    h_residual = h - h_steps * ROI_CW\n",
    "\n",
    "    return w, h, w_steps, h_steps, w_residual, h_residual\n",
    "\n",
    "def resize_normalize_image(im, size=(64, 64)):\n",
    "    image = np.array(im) \n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    return image \n",
    "    \n",
    "def transform_image(im, w_steps, h_steps):\n",
    "    \n",
    "    proposed_images = [] \n",
    "\n",
    "    for x in range(0, ROI_CW):\n",
    "        for y in range(0, ROI_CW):\n",
    "            for i in range(x + 1, ROI_CW):\n",
    "                for j in range(y + 1, ROI_CW):\n",
    "                    _left = x * w_steps\n",
    "                    _top = y * h_steps\n",
    "                    _right = (i) * w_steps\n",
    "                    _bottom = (j) * h_steps\n",
    "\n",
    "                    cropped_image = im.copy()\n",
    "                    try:\n",
    "                        cropped_image = cropped_image[_top:_bottom + 1, _left:_right + 1]\n",
    "                        # print(\"Targets:\", _top, _left, _bottom, _right)\n",
    "                        # print(\"Cropped Image Dimensions:\", cropped_image.shape)\n",
    "                        cropped_image = resize_normalize_image(cropped_image)\n",
    "                        \n",
    "                        proposed_images.append(cropped_image)\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "    proposed_images = np.array(proposed_images)\n",
    "    return proposed_images\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image = Image.open(\"input_img.jpg\")\n",
    "\n",
    "output_path = 'output.png'\n",
    "\n",
    "output = rembg.remove(pil_image, bgcolor=(0, 0, 0, 0))\n",
    "output.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_image = Image.open(\"output.png\")\n",
    "c_image = t_image.crop(t_image.getbbox())\n",
    "c_image.save(\"Cropped.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_image = Image.open(\"Cropped.png\").convert(\"RGB\")\n",
    "t_image.show()\n",
    "conv_image = t_image.copy().save(\"Saved.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _a = \"C:/Users/Alaric/Documents/GitHub/CPE124_E01_2Q2324_GROUP_1_SERVICE_LEARNING_REPOSITORY/PlantClassificationModels/Segmented Herbal Leaf Images/Artocarpus Heterophyllus (Jackfruit)/100.jpg\"\n",
    "# a = cv2.imread(_a, cv2.IMREAD_ANYCOLOR)\n",
    "a = cv2.imread(\"Saved.jpg\", cv2.IMREAD_ANYCOLOR)\n",
    "a = resize_normalize_image(a)\n",
    "\n",
    "cv2.imshow(\"Hatdog\", a)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "a = np.array([a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[2.37711868e-12, 1.26288496e-14, 9.88510362e-18, 3.64579604e-16,\n",
       "         1.99770322e-11, 8.29168512e-29, 5.60054444e-13, 1.42231189e-15,\n",
       "         1.14129776e-07, 5.95177482e-07, 9.99999285e-01]], dtype=float32),\n",
       " array([10], dtype=int64),\n",
       " array(['Z-Background'], dtype='<U36'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict(a)\n",
    "pred_y = np.argmax(y, axis=1)\n",
    "label = le.classes_[pred_y]\n",
    "y, pred_y, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artocarpus Heterophyllus (Jackfruit)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1.jpg': ('Artocarpus Heterophyllus (Jackfruit)', 1.0)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "orig_folder = \"Segmented Herbal Leaf Images\"\n",
    "\n",
    "total_plant_class_tally = {}\n",
    "\n",
    "for plant_class in os.listdir(orig_folder):\n",
    "    print(plant_class)\n",
    "    plant_class_predictions = {}\n",
    "\n",
    "    for testing_image in tqdm(os.listdir(os.path.join(orig_folder, plant_class))):\n",
    "        \n",
    "        im = load_image(os.path.join(orig_folder, plant_class, testing_image))\n",
    "        w, h, w_steps, h_steps, w_residual, h_residual = get_dimensions(im)\n",
    "        \n",
    "        if GET_ROI_TRANSFORMATIONS:\n",
    "            proposed_images = transform_image(im, w_steps, h_steps)\n",
    "        \n",
    "        else:\n",
    "            proposed_images = np.array([resize_normalize_image(im, (64, 64))])\n",
    "\n",
    "\n",
    "        _im = proposed_images[0]\n",
    "        _im = np.array(_im)\n",
    "\n",
    "        _im = rotate_image(_im, 36)\n",
    "        # cv2.imshow(\"hatdog\", _im)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "        raw_y = model.predict(proposed_images)\n",
    "        raw_y = np.array(raw_y)\n",
    "        pred_y = np.argmax(raw_y, axis=1)\n",
    "        predict_dict = {}\n",
    "        for i in pred_y:\n",
    "            predict_dict[i] = predict_dict.get(i, 0) + 1\n",
    "\n",
    "        transformed_dict = {}\n",
    "        for predict in predict_dict:\n",
    "            transformed_dict[le.classes_[predict]] = predict_dict[predict] / len(pred_y)\n",
    "\n",
    "        x = list(dict(sorted(transformed_dict.items(), key=lambda x:x[1], reverse=True)).items())[0]\n",
    "        \n",
    "        plant_class_predictions[testing_image] = x\n",
    "        \n",
    "        break\n",
    "    print(plant_class_predictions)\n",
    "\n",
    "    plant_class_tally = {}\n",
    "\n",
    "    for (file_name, (item_name, confidence)) in plant_class_predictions.items():\n",
    "        plant_class_tally[item_name] = plant_class_tally.get(item_name, 0) + 1\n",
    "\n",
    "    total_plant_class_tally[plant_class] = plant_class_tally\n",
    "\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Artocarpus Heterophyllus (Jackfruit)'], dtype='<U36')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_[pred_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Artocarpus Heterophyllus (Jackfruit)': {'Artocarpus Heterophyllus (Jackfruit)': 1}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_plant_class_tally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Artocarpus Heterophyllus (Jackfruit)': 1.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = {}\n",
    "\n",
    "for key, value in total_plant_class_tally.items():\n",
    "    total = 0 \n",
    "\n",
    "    for _k, _v in value.items():\n",
    "        total += _v\n",
    "\n",
    "    if key in value:\n",
    "        accuracies[key] = value[key] / total \n",
    "    else:\n",
    "        accuracies[key] = 0\n",
    "\n",
    "accuracies\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc = 0\n",
    "for _k, _v in accuracies.items():\n",
    "    total_acc += _v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
