{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Multilabel Classification Model for Herbal Classification Based on Symptoms or Herbal Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KHYLE MATTHEW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1360, 12)\n"
     ]
    }
   ],
   "source": [
    "train_path = 'dataset.csv'\n",
    "train_csv = pd.read_csv(train_path)\n",
    "train_csv.head()\n",
    "print(train_csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv['SYMPTOMS'].str.split().map(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLenSymp = train_csv['SYMPTOMS'].str.split().map(lambda x: len(x)).max()\n",
    "extra_tokens = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('medicalai/ClinicalBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_tokens = tokenizer(train_csv['SYMPTOMS'].values.tolist(),\n",
    "                           padding=True,\n",
    "                           truncation=True,\n",
    "                           max_length=maxLenSymp + extra_tokens,\n",
    "                           return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, csv_path, symptom_tokens, low_limit, high_limit):\n",
    "        self.data = pd.read_csv(csv_path).iloc[low_limit:high_limit].reset_index(drop=True)\n",
    "        self.symptom_tokens = symptom_tokens[low_limit:high_limit]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.symptom_tokens[idx],\n",
    "            self.data[self.data.columns[2]].iloc[idx],\n",
    "            self.data[self.data.columns[3]].iloc[idx],\n",
    "            self.data[self.data.columns[4]].iloc[idx],\n",
    "            self.data[self.data.columns[5]].iloc[idx],\n",
    "            self.data[self.data.columns[6]].iloc[idx],\n",
    "            self.data[self.data.columns[7]].iloc[idx],\n",
    "            self.data[self.data.columns[8]].iloc[idx],\n",
    "            self.data[self.data.columns[9]].iloc[idx],\n",
    "            self.data[self.data.columns[10]].iloc[idx],\n",
    "            self.data[self.data.columns[11]].iloc[idx]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ClassificationDataset(train_path, symptom_tokens, 0, int(len(train_csv) * 0.8))\n",
    "test_data = ClassificationDataset(train_path, symptom_tokens, int(len(train_csv) * 0.8), int(len(train_csv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=32, drop_last=True)\n",
    "test_dataLoader = DataLoader(test_data, shuffle=True, batch_size=32, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.embedding = AutoModel.from_pretrained('medicalai/ClinicalBERT')\n",
    "        self.embedding.config.pad_token_id\n",
    "        for param in self.embedding.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # self.rnn_symptom = nn.LSTM(input_size=768, hidden_size=64, bidirectional=True, batch_first=True)\n",
    "        self.rnn_symptom = nn.LSTM(input_size=768, hidden_size=64, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        f_in = 128\n",
    "\n",
    "        self.jackfruit = nn.Linear(in_features=f_in, out_features=1)\n",
    "        self.sambong = nn.Linear(in_features=f_in, out_features=1)\n",
    "        self.lemon = nn.Linear(in_features=f_in, out_features=1)\n",
    "        self.jasmine = nn.Linear(in_features=f_in, out_features=1)\n",
    "        self.mango = nn.Linear(in_features=f_in, out_features=1)\n",
    "        self.mint = nn.Linear(in_features=f_in, out_features=1)\n",
    "        self.ampalaya = nn.Linear(in_features=f_in, out_features=1)\n",
    "        self.malunggay = nn.Linear(in_features=f_in, out_features=1)\n",
    "        self.guava = nn.Linear(in_features=f_in, out_features=1)\n",
    "        self.lagundi = nn.Linear(in_features=f_in, out_features=1)\n",
    "\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, symptom):\n",
    "        symptom_embedding = self.embedding(symptom).last_hidden_state\n",
    "        symptom_features = self.rnn_symptom(symptom_embedding)[0][:, -1, :]\n",
    "        \n",
    "        \n",
    "        jackfruit_classify = self.act(self.jackfruit(symptom_features))\n",
    "        sambong_classify = self.act(self.sambong(symptom_features))\n",
    "        lemon_classify = self.act(self.lemon(symptom_features))\n",
    "        jasmine_classify = self.act(self.jasmine(symptom_features))\n",
    "        mango_classify = self.act(self.mango(symptom_features))\n",
    "        mint_classify = self.act(self.mint(symptom_features))\n",
    "        ampalaya_classify = self.act(self.ampalaya(symptom_features))\n",
    "        malunggay_classify = self.act(self.malunggay(symptom_features))\n",
    "        guava_classify = self.act(self.guava(symptom_features))\n",
    "        lagundi_classify = self.act(self.lagundi(symptom_features))\n",
    "\n",
    "        return (\n",
    "            jackfruit_classify,\n",
    "            sambong_classify,\n",
    "            lemon_classify,\n",
    "            jasmine_classify,\n",
    "            mango_classify,\n",
    "            mint_classify,\n",
    "            ampalaya_classify,\n",
    "            malunggay_classify,\n",
    "            guava_classify,\n",
    "            lagundi_classify\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KHYLE MATTHEW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = Classifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Train 1: Loss Jackfruit: 0.4360 || Loss Sambong: 0.6798 || Loss Lemon: 0.4541 || Loss Jasmine: 0.4610 || Loss Mango: 0.4751 || Loss Mint: 0.4946 || Loss Ampalaya: 0.3794 || Loss Malunggay: 0.3979 || Loss Guava: 0.5399 || Loss Lagundi: 0.4726 || Loss Total: 0.0000 || Acc Jackfruit: 0.8640 || Acc Sambong: 0.5478 || Acc Lemon: 0.8401 || Acc Jasmine: 0.8290 || Acc Mango: 0.8116 || Acc Mint: 0.8070 || Acc Ampalaya: 0.8759 || Acc Malunggay: 0.8851 || Acc Guava: 0.7849 || Acc Lagundi: 0.8336 || Acc Total: 0.8079al: 0.8187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Test 1: Loss Jackfruit: 0.3700 || Loss Sambong: 0.6662 || Loss Lemon: 0.2935 || Loss Jasmine: 0.3962 || Loss Mango: 0.4564 || Loss Mint: 0.4771 || Loss Ampalaya: 0.2974 || Loss Malunggay: 0.3744 || Loss Guava: 0.4044 || Loss Lagundi: 0.3736 || Loss Total: 0.0000 || Acc Jackfruit: 0.8789 || Acc Sambong: 0.5977 || Acc Lemon: 0.9141 || Acc Jasmine: 0.8633 || Acc Mango: 0.8320 || Acc Mint: 0.8164 || Acc Ampalaya: 0.9141 || Acc Malunggay: 0.8828 || Acc Guava: 0.8711 || Acc Lagundi: 0.8750 || Acc Total: 0.8445\n",
      "Epoch Train 2: Loss Jackfruit: 0.3741 || Loss Sambong: 0.6439 || Loss Lemon: 0.3784 || Loss Jasmine: 0.4335 || Loss Mango: 0.4217 || Loss Mint: 0.4248 || Loss Ampalaya: 0.2953 || Loss Malunggay: 0.3445 || Loss Guava: 0.4962 || Loss Lagundi: 0.4120 || Loss Total: 0.0000 || Acc Jackfruit: 0.8750 || Acc Sambong: 0.6324 || Acc Lemon: 0.8750 || Acc Jasmine: 0.8419 || Acc Mango: 0.8502 || Acc Mint: 0.8474 || Acc Ampalaya: 0.9127 || Acc Malunggay: 0.8915 || Acc Guava: 0.8024 || Acc Lagundi: 0.8539 || Acc Total: 0.8382al: 0.8469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Test 2: Loss Jackfruit: 0.3601 || Loss Sambong: 0.6345 || Loss Lemon: 0.3107 || Loss Jasmine: 0.3883 || Loss Mango: 0.4519 || Loss Mint: 0.4714 || Loss Ampalaya: 0.3003 || Loss Malunggay: 0.3702 || Loss Guava: 0.3876 || Loss Lagundi: 0.3529 || Loss Total: 0.0000 || Acc Jackfruit: 0.8828 || Acc Sambong: 0.6641 || Acc Lemon: 0.9062 || Acc Jasmine: 0.8672 || Acc Mango: 0.8320 || Acc Mint: 0.8203 || Acc Ampalaya: 0.9062 || Acc Malunggay: 0.8789 || Acc Guava: 0.8750 || Acc Lagundi: 0.8867 || Acc Total: 0.8520\n",
      "Epoch Train 3: Loss Jackfruit: 0.3692 || Loss Sambong: 0.6168 || Loss Lemon: 0.3722 || Loss Jasmine: 0.4307 || Loss Mango: 0.4167 || Loss Mint: 0.4177 || Loss Ampalaya: 0.2861 || Loss Malunggay: 0.3318 || Loss Guava: 0.4940 || Loss Lagundi: 0.3981 || Loss Total: 0.0000 || Acc Jackfruit: 0.8750 || Acc Sambong: 0.6756 || Acc Lemon: 0.8750 || Acc Jasmine: 0.8419 || Acc Mango: 0.8502 || Acc Mint: 0.8474 || Acc Ampalaya: 0.9127 || Acc Malunggay: 0.8915 || Acc Guava: 0.8024 || Acc Lagundi: 0.8539 || Acc Total: 0.8426al: 0.8625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Test 3: Loss Jackfruit: 0.3357 || Loss Sambong: 0.5794 || Loss Lemon: 0.2866 || Loss Jasmine: 0.3699 || Loss Mango: 0.4569 || Loss Mint: 0.4646 || Loss Ampalaya: 0.2925 || Loss Malunggay: 0.3504 || Loss Guava: 0.3690 || Loss Lagundi: 0.3527 || Loss Total: 0.0000 || Acc Jackfruit: 0.8906 || Acc Sambong: 0.7188 || Acc Lemon: 0.9141 || Acc Jasmine: 0.8711 || Acc Mango: 0.8281 || Acc Mint: 0.8086 || Acc Ampalaya: 0.9062 || Acc Malunggay: 0.8789 || Acc Guava: 0.8789 || Acc Lagundi: 0.8750 || Acc Total: 0.8570\n",
      "Epoch Train 4: Loss Jackfruit: 0.3629 || Loss Sambong: 0.5703 || Loss Lemon: 0.3641 || Loss Jasmine: 0.4218 || Loss Mango: 0.4072 || Loss Mint: 0.3981 || Loss Ampalaya: 0.2746 || Loss Malunggay: 0.3247 || Loss Guava: 0.4899 || Loss Lagundi: 0.3857 || Loss Total: 0.0000 || Acc Jackfruit: 0.8750 || Acc Sambong: 0.6949 || Acc Lemon: 0.8750 || Acc Jasmine: 0.8419 || Acc Mango: 0.8502 || Acc Mint: 0.8474 || Acc Ampalaya: 0.9127 || Acc Malunggay: 0.8915 || Acc Guava: 0.8024 || Acc Lagundi: 0.8539 || Acc Total: 0.8445al: 0.8187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Test 4: Loss Jackfruit: 0.3479 || Loss Sambong: 0.5600 || Loss Lemon: 0.3036 || Loss Jasmine: 0.3746 || Loss Mango: 0.4160 || Loss Mint: 0.4233 || Loss Ampalaya: 0.2724 || Loss Malunggay: 0.3360 || Loss Guava: 0.3946 || Loss Lagundi: 0.3249 || Loss Total: 0.0000 || Acc Jackfruit: 0.8828 || Acc Sambong: 0.6680 || Acc Lemon: 0.9062 || Acc Jasmine: 0.8672 || Acc Mango: 0.8359 || Acc Mint: 0.8203 || Acc Ampalaya: 0.9062 || Acc Malunggay: 0.8789 || Acc Guava: 0.8750 || Acc Lagundi: 0.8828 || Acc Total: 0.8523\n",
      "Epoch Train 5: Loss Jackfruit: 0.3567 || Loss Sambong: 0.5333 || Loss Lemon: 0.3522 || Loss Jasmine: 0.4123 || Loss Mango: 0.3889 || Loss Mint: 0.3867 || Loss Ampalaya: 0.2663 || Loss Malunggay: 0.3037 || Loss Guava: 0.4782 || Loss Lagundi: 0.3678 || Loss Total: 0.0000 || Acc Jackfruit: 0.8750 || Acc Sambong: 0.7178 || Acc Lemon: 0.8750 || Acc Jasmine: 0.8419 || Acc Mango: 0.8502 || Acc Mint: 0.8474 || Acc Ampalaya: 0.9127 || Acc Malunggay: 0.8915 || Acc Guava: 0.8024 || Acc Lagundi: 0.8539 || Acc Total: 0.8468al: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Test 5: Loss Jackfruit: 0.3485 || Loss Sambong: 0.4982 || Loss Lemon: 0.2829 || Loss Jasmine: 0.3600 || Loss Mango: 0.3902 || Loss Mint: 0.4292 || Loss Ampalaya: 0.2543 || Loss Malunggay: 0.3177 || Loss Guava: 0.3817 || Loss Lagundi: 0.3232 || Loss Total: 0.0000 || Acc Jackfruit: 0.8828 || Acc Sambong: 0.7617 || Acc Lemon: 0.9141 || Acc Jasmine: 0.8672 || Acc Mango: 0.8438 || Acc Mint: 0.8086 || Acc Ampalaya: 0.9062 || Acc Malunggay: 0.8750 || Acc Guava: 0.8906 || Acc Lagundi: 0.8789 || Acc Total: 0.8629\n",
      "Epoch Train 6: Loss Jackfruit: 0.3501 || Loss Sambong: 0.4898 || Loss Lemon: 0.3386 || Loss Jasmine: 0.4068 || Loss Mango: 0.3672 || Loss Mint: 0.3673 || Loss Ampalaya: 0.2503 || Loss Malunggay: 0.2940 || Loss Guava: 0.4743 || Loss Lagundi: 0.3477 || Loss Total: 0.0000 || Acc Jackfruit: 0.8750 || Acc Sambong: 0.7638 || Acc Lemon: 0.8750 || Acc Jasmine: 0.8419 || Acc Mango: 0.8502 || Acc Mint: 0.8474 || Acc Ampalaya: 0.9127 || Acc Malunggay: 0.8915 || Acc Guava: 0.8024 || Acc Lagundi: 0.8603 || Acc Total: 0.8520al: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Test 6: Loss Jackfruit: 0.3469 || Loss Sambong: 0.4642 || Loss Lemon: 0.2676 || Loss Jasmine: 0.3569 || Loss Mango: 0.3724 || Loss Mint: 0.3898 || Loss Ampalaya: 0.2415 || Loss Malunggay: 0.2987 || Loss Guava: 0.3561 || Loss Lagundi: 0.2923 || Loss Total: 0.0000 || Acc Jackfruit: 0.8789 || Acc Sambong: 0.7891 || Acc Lemon: 0.9180 || Acc Jasmine: 0.8711 || Acc Mango: 0.8359 || Acc Mint: 0.8125 || Acc Ampalaya: 0.9102 || Acc Malunggay: 0.8828 || Acc Guava: 0.8750 || Acc Lagundi: 0.8789 || Acc Total: 0.8652\n",
      "Epoch Train 7: Loss Jackfruit: 0.3331 || Loss Sambong: 0.4397 || Loss Lemon: 0.3365 || Loss Jasmine: 0.3950 || Loss Mango: 0.3525 || Loss Mint: 0.3379 || Loss Ampalaya: 0.2426 || Loss Malunggay: 0.2872 || Loss Guava: 0.4634 || Loss Lagundi: 0.3283 || Loss Total: 0.0000 || Acc Jackfruit: 0.8750 || Acc Sambong: 0.7960 || Acc Lemon: 0.8750 || Acc Jasmine: 0.8419 || Acc Mango: 0.8502 || Acc Mint: 0.8493 || Acc Ampalaya: 0.9127 || Acc Malunggay: 0.8915 || Acc Guava: 0.8024 || Acc Lagundi: 0.8676 || Acc Total: 0.8562al: 0.8594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Test 7: Loss Jackfruit: 0.3345 || Loss Sambong: 0.4272 || Loss Lemon: 0.2789 || Loss Jasmine: 0.3389 || Loss Mango: 0.3493 || Loss Mint: 0.3444 || Loss Ampalaya: 0.2359 || Loss Malunggay: 0.2912 || Loss Guava: 0.3586 || Loss Lagundi: 0.2629 || Loss Total: 0.0000 || Acc Jackfruit: 0.8789 || Acc Sambong: 0.8086 || Acc Lemon: 0.9062 || Acc Jasmine: 0.8672 || Acc Mango: 0.8359 || Acc Mint: 0.8242 || Acc Ampalaya: 0.9062 || Acc Malunggay: 0.8789 || Acc Guava: 0.8789 || Acc Lagundi: 0.9102 || Acc Total: 0.8695\n",
      "Epoch Train 8: Loss Jackfruit: 0.3287 || Loss Sambong: 0.4085 || Loss Lemon: 0.3260 || Loss Jasmine: 0.3783 || Loss Mango: 0.3420 || Loss Mint: 0.3110 || Loss Ampalaya: 0.2443 || Loss Malunggay: 0.2790 || Loss Guava: 0.4504 || Loss Lagundi: 0.3167 || Loss Total: 0.0000 || Acc Jackfruit: 0.8750 || Acc Sambong: 0.8189 || Acc Lemon: 0.8750 || Acc Jasmine: 0.8419 || Acc Mango: 0.8502 || Acc Mint: 0.8686 || Acc Ampalaya: 0.9127 || Acc Malunggay: 0.8915 || Acc Guava: 0.8024 || Acc Lagundi: 0.8759 || Acc Total: 0.8612al: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Test 8: Loss Jackfruit: 0.3285 || Loss Sambong: 0.3924 || Loss Lemon: 0.2678 || Loss Jasmine: 0.3241 || Loss Mango: 0.3378 || Loss Mint: 0.3269 || Loss Ampalaya: 0.2364 || Loss Malunggay: 0.3039 || Loss Guava: 0.3359 || Loss Lagundi: 0.2445 || Loss Total: 0.0000 || Acc Jackfruit: 0.8750 || Acc Sambong: 0.8438 || Acc Lemon: 0.9141 || Acc Jasmine: 0.8672 || Acc Mango: 0.8359 || Acc Mint: 0.8320 || Acc Ampalaya: 0.9023 || Acc Malunggay: 0.8750 || Acc Guava: 0.8906 || Acc Lagundi: 0.9102 || Acc Total: 0.8746\n",
      "Epoch Train 9: Loss Jackfruit: 0.3124 || Loss Sambong: 0.3557 || Loss Lemon: 0.3192 || Loss Jasmine: 0.3713 || Loss Mango: 0.3062 || Loss Mint: 0.2789 || Loss Ampalaya: 0.2360 || Loss Malunggay: 0.2778 || Loss Guava: 0.4434 || Loss Lagundi: 0.2842 || Loss Total: 0.0000 || Acc Jackfruit: 0.8768 || Acc Sambong: 0.8511 || Acc Lemon: 0.8750 || Acc Jasmine: 0.8428 || Acc Mango: 0.8511 || Acc Mint: 0.8869 || Acc Ampalaya: 0.9127 || Acc Malunggay: 0.8915 || Acc Guava: 0.8125 || Acc Lagundi: 0.8869 || Acc Total: 0.8687al: 0.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Test 9: Loss Jackfruit: 0.3038 || Loss Sambong: 0.3422 || Loss Lemon: 0.2643 || Loss Jasmine: 0.3855 || Loss Mango: 0.3104 || Loss Mint: 0.3200 || Loss Ampalaya: 0.2074 || Loss Malunggay: 0.2811 || Loss Guava: 0.3605 || Loss Lagundi: 0.2404 || Loss Total: 0.0000 || Acc Jackfruit: 0.8789 || Acc Sambong: 0.8672 || Acc Lemon: 0.9141 || Acc Jasmine: 0.8750 || Acc Mango: 0.8438 || Acc Mint: 0.8359 || Acc Ampalaya: 0.9141 || Acc Malunggay: 0.8789 || Acc Guava: 0.9023 || Acc Lagundi: 0.9219 || Acc Total: 0.8832\n",
      "Epoch Train 10: Loss Jackfruit: 0.3002 || Loss Sambong: 0.3236 || Loss Lemon: 0.3122 || Loss Jasmine: 0.3456 || Loss Mango: 0.2962 || Loss Mint: 0.2484 || Loss Ampalaya: 0.2216 || Loss Malunggay: 0.2705 || Loss Guava: 0.4093 || Loss Lagundi: 0.2601 || Loss Total: 0.0000 || Acc Jackfruit: 0.8787 || Acc Sambong: 0.8768 || Acc Lemon: 0.8750 || Acc Jasmine: 0.8483 || Acc Mango: 0.8557 || Acc Mint: 0.8952 || Acc Ampalaya: 0.9127 || Acc Malunggay: 0.8925 || Acc Guava: 0.8300 || Acc Lagundi: 0.8943 || Acc Total: 0.8759al: 0.8844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Test 10: Loss Jackfruit: 0.2843 || Loss Sambong: 0.2624 || Loss Lemon: 0.2665 || Loss Jasmine: 0.3000 || Loss Mango: 0.2926 || Loss Mint: 0.2544 || Loss Ampalaya: 0.2257 || Loss Malunggay: 0.2915 || Loss Guava: 0.2993 || Loss Lagundi: 0.1985 || Loss Total: 0.0000 || Acc Jackfruit: 0.8789 || Acc Sambong: 0.9258 || Acc Lemon: 0.9141 || Acc Jasmine: 0.8750 || Acc Mango: 0.8398 || Acc Mint: 0.9023 || Acc Ampalaya: 0.9062 || Acc Malunggay: 0.8711 || Acc Guava: 0.9062 || Acc Lagundi: 0.9297 || Acc Total: 0.8949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_loss_jackfruit, train_loss_sambong, train_loss_lemon, train_loss_jasmine, train_loss_mango, train_loss_mint, train_loss_ampalaya, train_loss_malunggay, train_loss_guava, train_loss_lagundi = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "\n",
    "    train_acc = 0\n",
    "    train_acc_jackfruit = 0\n",
    "    train_acc_sambong = 0\n",
    "    train_acc_lemon = 0\n",
    "    train_acc_jasmine = 0\n",
    "    train_acc_mango = 0\n",
    "    train_acc_mint = 0\n",
    "    train_acc_ampalaya = 0\n",
    "    train_acc_malunggay = 0\n",
    "    train_acc_guava = 0\n",
    "    train_acc_lagundi = 0\n",
    "\n",
    "    test_loss = 0\n",
    "    test_loss_jackfruit = 0\n",
    "    test_loss_sambong = 0\n",
    "    test_loss_lemon = 0\n",
    "    test_loss_jasmine = 0\n",
    "    test_loss_mango = 0\n",
    "    test_loss_mint = 0\n",
    "    test_loss_ampalaya = 0\n",
    "    test_loss_malunggay = 0\n",
    "    test_loss_guava = 0\n",
    "    test_loss_lagundi = 0\n",
    "\n",
    "    test_acc = 0\n",
    "    test_acc_jackfruit = 0\n",
    "    test_acc_sambong = 0\n",
    "    test_acc_lemon = 0\n",
    "    test_acc_jasmine = 0\n",
    "    test_acc_mango = 0\n",
    "    test_acc_mint = 0\n",
    "    test_acc_ampalaya = 0\n",
    "    test_acc_malunggay = 0\n",
    "    test_acc_guava = 0\n",
    "    test_acc_lagundi = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (index, (symptom, jackfruit_true, sambong_true, lemon_true, jasmine_true, mango_true, mint_true, ampalaya_true, malunggay_true, guava_true, lagundi_true)) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        symptom, jackfruit_true, sambong_true, lemon_true, jasmine_true, mango_true, mint_true, ampalaya_true, malunggay_true, guava_true, lagundi_true = symptom.to(device), jackfruit_true.to(device), sambong_true.to(device), lemon_true.to(device), jasmine_true.to(device), mango_true.to(device), mint_true.to(device), ampalaya_true.to(device), malunggay_true.to(device), guava_true.to(device), lagundi_true.to(device)\n",
    "        \n",
    "        jackfruit_classify, sambong_classify, lemon_classify, jasmine_classify, mango_classify, mint_classify, ampalaya_classify, malunggay_classify, guava_classify, lagundi_classify = model(symptom)\n",
    "\n",
    "        loss_jackfruit = loss_fn(jackfruit_classify, jackfruit_true.float().unsqueeze(dim=1))\n",
    "        loss_sambong = loss_fn(sambong_classify, sambong_true.float().unsqueeze(dim=1))\n",
    "        loss_lemon = loss_fn(lemon_classify, lemon_true.float().unsqueeze(dim=1))\n",
    "        loss_jasmine = loss_fn(jasmine_classify, jasmine_true.float().unsqueeze(dim=1))\n",
    "        loss_mango = loss_fn(mango_classify, mango_true.float().unsqueeze(dim=1))\n",
    "        loss_mint = loss_fn(mint_classify, mint_true.float().unsqueeze(dim=1))\n",
    "        loss_ampalaya = loss_fn(ampalaya_classify, ampalaya_true.float().unsqueeze(dim=1))\n",
    "        loss_malunggay = loss_fn(malunggay_classify, malunggay_true.float().unsqueeze(dim=1))\n",
    "        loss_guava = loss_fn(guava_classify, guava_true.float().unsqueeze(dim=1))\n",
    "        loss_lagundi = loss_fn(lagundi_classify, lagundi_true.float().unsqueeze(dim=1))\n",
    "\n",
    "        loss = loss_jackfruit + loss_sambong + loss_lemon + loss_jasmine + loss_mango + loss_mint + loss_ampalaya + loss_malunggay + loss_guava + loss_lagundi\n",
    "\n",
    "        train_loss_jackfruit += loss_jackfruit.item()\n",
    "        train_loss_sambong += loss_sambong.item()\n",
    "        train_loss_lemon += loss_lemon.item()\n",
    "        train_loss_jasmine += loss_jasmine.item()\n",
    "        train_loss_mango += loss_mango.item()\n",
    "        train_loss_mint += loss_mint.item()\n",
    "        train_loss_ampalaya += loss_ampalaya.item()\n",
    "        train_loss_malunggay += loss_malunggay.item()\n",
    "        train_loss_guava += loss_guava.item()\n",
    "        train_loss_lagundi += loss_lagundi.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        acc_jackfruit = (jackfruit_classify.round() == jackfruit_true.float().unsqueeze(dim=1)).sum().item() / jackfruit_classify.size(0)\n",
    "        acc_sambong = (sambong_classify.round() == sambong_true.float().unsqueeze(dim=1)).sum().item() / sambong_classify.size(0)\n",
    "        acc_lemon = (lemon_classify.round() == lemon_true.float().unsqueeze(dim=1)).sum().item() / lemon_classify.size(0)\n",
    "        acc_jasmine = (jasmine_classify.round() == jasmine_true.float().unsqueeze(dim=1)).sum().item() / jasmine_classify.size(0)\n",
    "        acc_mango = (mango_classify.round() == mango_true.float().unsqueeze(dim=1)).sum().item() / mango_classify.size(0)\n",
    "        acc_mint = (mint_classify.round() == mint_true.float().unsqueeze(dim=1)).sum().item() / mint_classify.size(0)\n",
    "        acc_ampalaya = (ampalaya_classify.round() == ampalaya_true.float().unsqueeze(dim=1)).sum().item() / ampalaya_classify.size(0)\n",
    "        acc_malunggay = (malunggay_classify.round() == malunggay_true.float().unsqueeze(dim=1)).sum().item() / malunggay_classify.size(0)\n",
    "        acc_guava = (guava_classify.round() == guava_true.float().unsqueeze(dim=1)).sum().item() / guava_classify.size(0)\n",
    "        acc_lagundi = (lagundi_classify.round() == lagundi_true.float().unsqueeze(dim=1)).sum().item() / lagundi_classify.size(0)\n",
    "\n",
    "        acc = (acc_jackfruit + acc_sambong + acc_lemon + acc_jasmine + acc_mango + acc_mint + acc_ampalaya + acc_malunggay + acc_guava + acc_lagundi) / 10\n",
    "\n",
    "        train_acc += acc\n",
    "        train_acc_jackfruit += acc_jackfruit\n",
    "        train_acc_sambong += acc_sambong\n",
    "        train_acc_lemon += acc_lemon\n",
    "        train_acc_jasmine += acc_jasmine\n",
    "        train_acc_mango += acc_mango\n",
    "        train_acc_mint += acc_mint\n",
    "        train_acc_ampalaya += acc_ampalaya\n",
    "        train_acc_malunggay += acc_malunggay\n",
    "        train_acc_guava += acc_guava\n",
    "        train_acc_lagundi += acc_lagundi\n",
    "\n",
    "        print(\"Epoch {}: Batch: {}/{} || Loss Jackfruit: {:.4f} || Loss Sambong: {:.4f} || Loss Lemon: {:.4f} || Loss Jasmine: {:.4f} || Loss Mango: {:.4f} || Loss Mint: {:.4f} || Loss Ampalaya: {:.4f} || Loss Malunggay: {:.4f} || Loss Guava: {:.4f} || Loss Lagundi: {:.4f} || Loss Total: {:.4f} || Acc Jackfruit: {:.4f} || Acc Sambong: {:.4f} || Acc Lemon: {:.4f} || Acc Jasmine: {:.4f} || Acc Mango: {:.4f} || Acc Mint: {:.4f} || Acc Ampalaya: {:.4f} || Acc Malunggay: {:.4f} || Acc Guava: {:.4f} || Acc Lagundi: {:.4f} || Acc Total: {:.4f}\".format(\n",
    "            epoch+1,\n",
    "            index,\n",
    "            len(train_dataloader),\n",
    "            loss_jackfruit,\n",
    "            loss_sambong,\n",
    "            loss_lemon,\n",
    "            loss_jasmine,\n",
    "            loss_mango,\n",
    "            loss_mint,\n",
    "            loss_ampalaya,\n",
    "            loss_malunggay,\n",
    "            loss_guava,\n",
    "            loss_lagundi,\n",
    "            loss,\n",
    "            acc_jackfruit,\n",
    "            acc_sambong,\n",
    "            acc_lemon,\n",
    "            acc_jasmine,\n",
    "            acc_mango,\n",
    "            acc_mint,\n",
    "            acc_ampalaya,\n",
    "            acc_malunggay,\n",
    "            acc_guava,\n",
    "            acc_lagundi,\n",
    "            acc\n",
    "        ), end='\\r')\n",
    "\n",
    "    print(\"Epoch Train {}: Loss Jackfruit: {:.4f} || Loss Sambong: {:.4f} || Loss Lemon: {:.4f} || Loss Jasmine: {:.4f} || Loss Mango: {:.4f} || Loss Mint: {:.4f} || Loss Ampalaya: {:.4f} || Loss Malunggay: {:.4f} || Loss Guava: {:.4f} || Loss Lagundi: {:.4f} || Loss Total: {:.4f} || Acc Jackfruit: {:.4f} || Acc Sambong: {:.4f} || Acc Lemon: {:.4f} || Acc Jasmine: {:.4f} || Acc Mango: {:.4f} || Acc Mint: {:.4f} || Acc Ampalaya: {:.4f} || Acc Malunggay: {:.4f} || Acc Guava: {:.4f} || Acc Lagundi: {:.4f} || Acc Total: {:.4f}\".format(\n",
    "        epoch+1,\n",
    "        train_loss_jackfruit / len(train_dataloader),\n",
    "        train_loss_sambong / len(train_dataloader),\n",
    "        train_loss_lemon / len(train_dataloader),\n",
    "        train_loss_jasmine / len(train_dataloader),\n",
    "        train_loss_mango / len(train_dataloader),\n",
    "        train_loss_mint / len(train_dataloader),\n",
    "        train_loss_ampalaya / len(train_dataloader),\n",
    "        train_loss_malunggay / len(train_dataloader),\n",
    "        train_loss_guava / len(train_dataloader),\n",
    "        train_loss_lagundi / len(train_dataloader),\n",
    "        train_loss / len(train_dataloader),\n",
    "        train_acc_jackfruit / len(train_dataloader),\n",
    "        train_acc_sambong / len(train_dataloader),\n",
    "        train_acc_lemon / len(train_dataloader),\n",
    "        train_acc_jasmine / len(train_dataloader),\n",
    "        train_acc_mango / len(train_dataloader),\n",
    "        train_acc_mint / len(train_dataloader),\n",
    "        train_acc_ampalaya / len(train_dataloader),\n",
    "        train_acc_malunggay / len(train_dataloader),\n",
    "        train_acc_guava / len(train_dataloader),\n",
    "        train_acc_lagundi / len(train_dataloader),\n",
    "        train_acc / len(train_dataloader)\n",
    "    ))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for symptom, jackfruit_true, sambong_true, lemon_true, jasmine_true, mango_true, mint_true, ampalaya_true, malunggay_true, guava_true, lagundi_true in tqdm(test_dataLoader):\n",
    "        with torch.no_grad():\n",
    "            symptom, jackfruit_true, sambong_true, lemon_true, jasmine_true, mango_true, mint_true, ampalaya_true, malunggay_true, guava_true, lagundi_true = symptom.to(device), jackfruit_true.to(device), sambong_true.to(device), lemon_true.to(device), jasmine_true.to(device), mango_true.to(device), mint_true.to(device), ampalaya_true.to(device), malunggay_true.to(device), guava_true.to(device), lagundi_true.to(device)\n",
    "\n",
    "            jackfruit_classify, sambong_classify, lemon_classify, jasmine_classify, mango_classify, mint_classify, ampalaya_classify, malunggay_classify, guava_classify, lagundi_classify = model(symptom)\n",
    "\n",
    "            loss_jackfruit = loss_fn(jackfruit_classify, jackfruit_true.float().unsqueeze(dim=1))\n",
    "            loss_sambong = loss_fn(sambong_classify, sambong_true.float().unsqueeze(dim=1))\n",
    "            loss_lemon = loss_fn(lemon_classify, lemon_true.float().unsqueeze(dim=1))\n",
    "            loss_jasmine = loss_fn(jasmine_classify, jasmine_true.float().unsqueeze(dim=1))\n",
    "            loss_mango = loss_fn(mango_classify, mango_true.float().unsqueeze(dim=1))\n",
    "            loss_mint = loss_fn(mint_classify, mint_true.float().unsqueeze(dim=1))\n",
    "            loss_ampalaya = loss_fn(ampalaya_classify, ampalaya_true.float().unsqueeze(dim=1))\n",
    "            loss_malunggay = loss_fn(malunggay_classify, malunggay_true.float().unsqueeze(dim=1))\n",
    "            loss_guava = loss_fn(guava_classify, guava_true.float().unsqueeze(dim=1))\n",
    "            loss_lagundi = loss_fn(lagundi_classify, lagundi_true.float().unsqueeze(dim=1))\n",
    "\n",
    "            loss = loss_jackfruit + loss_sambong + loss_lemon + loss_jasmine + loss_mango + loss_mint + loss_ampalaya + loss_malunggay + loss_guava + loss_lagundi\n",
    "        \n",
    "        test_loss_jackfruit += loss_jackfruit.item()\n",
    "        test_loss_sambong += loss_sambong.item()\n",
    "        test_loss_lemon += loss_lemon.item()\n",
    "        test_loss_jasmine += loss_jasmine.item()\n",
    "        test_loss_mango += loss_mango.item()\n",
    "        test_loss_mint += loss_mint.item()\n",
    "        test_loss_ampalaya += loss_ampalaya.item()\n",
    "        test_loss_malunggay += loss_malunggay.item()\n",
    "        test_loss_guava += loss_guava.item()\n",
    "        test_loss_lagundi += loss_lagundi.item()\n",
    "\n",
    "        acc_jackfruit = (jackfruit_classify.round() == jackfruit_true.float().unsqueeze(dim=1)).sum().item() / jackfruit_classify.size(0)\n",
    "        acc_sambong = (sambong_classify.round() == sambong_true.float().unsqueeze(dim=1)).sum().item() / sambong_classify.size(0)\n",
    "        acc_lemon = (lemon_classify.round() == lemon_true.float().unsqueeze(dim=1)).sum().item() / lemon_classify.size(0)\n",
    "        acc_jasmine = (jasmine_classify.round() == jasmine_true.float().unsqueeze(dim=1)).sum().item() / jasmine_classify.size(0)\n",
    "        acc_mango = (mango_classify.round() == mango_true.float().unsqueeze(dim=1)).sum().item() / mango_classify.size(0)\n",
    "        acc_mint = (mint_classify.round() == mint_true.float().unsqueeze(dim=1)).sum().item() / mint_classify.size(0)\n",
    "        acc_ampalaya = (ampalaya_classify.round() == ampalaya_true.float().unsqueeze(dim=1)).sum().item() / ampalaya_classify.size(0)\n",
    "        acc_malunggay = (malunggay_classify.round() == malunggay_true.float().unsqueeze(dim=1)).sum().item() / malunggay_classify.size(0)\n",
    "        acc_guava = (guava_classify.round() == guava_true.float().unsqueeze(dim=1)).sum().item() / guava_classify.size(0)\n",
    "        acc_lagundi = (lagundi_classify.round() == lagundi_true.float().unsqueeze(dim=1)).sum().item() / lagundi_classify.size(0)\n",
    "\n",
    "        acc = (acc_jackfruit + acc_sambong + acc_lemon + acc_jasmine + acc_mango + acc_mint + acc_ampalaya + acc_malunggay + acc_guava + acc_lagundi) / 10\n",
    "\n",
    "        test_acc += acc\n",
    "        test_acc_jackfruit += acc_jackfruit\n",
    "        test_acc_sambong += acc_sambong\n",
    "        test_acc_lemon += acc_lemon\n",
    "        test_acc_jasmine += acc_jasmine\n",
    "        test_acc_mango += acc_mango\n",
    "        test_acc_mint += acc_mint\n",
    "        test_acc_ampalaya += acc_ampalaya\n",
    "        test_acc_malunggay += acc_malunggay\n",
    "        test_acc_guava += acc_guava\n",
    "        test_acc_lagundi += acc_lagundi\n",
    "        \n",
    "    print(\"Epoch Test {}: Loss Jackfruit: {:.4f} || Loss Sambong: {:.4f} || Loss Lemon: {:.4f} || Loss Jasmine: {:.4f} || Loss Mango: {:.4f} || Loss Mint: {:.4f} || Loss Ampalaya: {:.4f} || Loss Malunggay: {:.4f} || Loss Guava: {:.4f} || Loss Lagundi: {:.4f} || Loss Total: {:.4f} || Acc Jackfruit: {:.4f} || Acc Sambong: {:.4f} || Acc Lemon: {:.4f} || Acc Jasmine: {:.4f} || Acc Mango: {:.4f} || Acc Mint: {:.4f} || Acc Ampalaya: {:.4f} || Acc Malunggay: {:.4f} || Acc Guava: {:.4f} || Acc Lagundi: {:.4f} || Acc Total: {:.4f}\".format(\n",
    "        epoch+1,\n",
    "        test_loss_jackfruit / len(test_dataLoader),\n",
    "        test_loss_sambong / len(test_dataLoader),\n",
    "        test_loss_lemon / len(test_dataLoader),\n",
    "        test_loss_jasmine / len(test_dataLoader),\n",
    "        test_loss_mango / len(test_dataLoader),\n",
    "        test_loss_mint / len(test_dataLoader),\n",
    "        test_loss_ampalaya / len(test_dataLoader),\n",
    "        test_loss_malunggay / len(test_dataLoader),\n",
    "        test_loss_guava / len(test_dataLoader),\n",
    "        test_loss_lagundi / len(test_dataLoader),\n",
    "        test_loss / len(test_dataLoader),\n",
    "        test_acc_jackfruit / len(test_dataLoader),\n",
    "        test_acc_sambong / len(test_dataLoader),\n",
    "        test_acc_lemon / len(test_dataLoader),\n",
    "        test_acc_jasmine / len(test_dataLoader),\n",
    "        test_acc_mango / len(test_dataLoader),\n",
    "        test_acc_mint / len(test_dataLoader),\n",
    "        test_acc_ampalaya / len(test_dataLoader),\n",
    "        test_acc_malunggay / len(test_dataLoader),\n",
    "        test_acc_guava / len(test_dataLoader),\n",
    "        test_acc_lagundi / len(test_dataLoader),\n",
    "        test_acc / len(test_dataLoader)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE MODEL USING PICKLE\n",
    "import pickle\n",
    "model_pkl_file = \"herbal_classifier_based_on_Symptoms\"  \n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m tryInput \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you please recommend me a herbal for headaches\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# ans_cols = [\"JACKFRUIT\", \"SAMBONG\", \"LEMON\", \"JASMINE\", \"MANGO\", \"MINT\", \"AMPALAYA\", \"MALUNGGAY\", \"GUAVA\", \"LAGUNDI\"]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# encoding = tokenizer(tryInput, return_tensors=\"pt\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# predicted_labels = [ans_cols[myIndex] for myIndex, label in enumerate(predictions) if label == 1.0]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# print(predicted_labels)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtryInput\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\KHYLE MATTHEW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\KHYLE MATTHEW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mClassifier.forward\u001b[1;34m(self, symptom)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, symptom):\n\u001b[1;32m---> 28\u001b[0m     symptom_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymptom\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m     29\u001b[0m     symptom_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_symptom(symptom_embedding)[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     32\u001b[0m     jackfruit_classify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjackfruit(symptom_features))\n",
      "File \u001b[1;32mc:\\Users\\KHYLE MATTHEW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\KHYLE MATTHEW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KHYLE MATTHEW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:802\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 802\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarn_if_padding_and_no_attention_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    803\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\KHYLE MATTHEW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:4518\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m   4515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   4517\u001b[0m \u001b[38;5;66;03m# Check only the first and last input IDs to reduce overhead.\u001b[39;00m\n\u001b[1;32m-> 4518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[0;32m   4519\u001b[0m     warn_string \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4520\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4521\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/troubleshooting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#incorrect-output-when-padding-tokens-arent-masked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4523\u001b[0m     )\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;66;03m# If the pad token is equal to either BOS, EOS, or SEP, we do not know whether the user should use an\u001b[39;00m\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;66;03m# attention_mask or not. In this case, we should still show a warning because this is a rare case.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "tryInput = \"Can you please recommend me a herbal for headaches\"\n",
    "# ans_cols = [\"JACKFRUIT\", \"SAMBONG\", \"LEMON\", \"JASMINE\", \"MANGO\", \"MINT\", \"AMPALAYA\", \"MALUNGGAY\", \"GUAVA\", \"LAGUNDI\"]\n",
    "\n",
    "# encoding = tokenizer(tryInput, return_tensors=\"pt\")\n",
    "# encoding = {k: v.to(model) for k, v in encoding.items()}\n",
    "\n",
    "# outputs = model(**encoding)\n",
    "# logits = outputs.logits\n",
    "\n",
    "# sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "# probs = sigmoid(logits.squeeze().cpu())\n",
    "# predictions = np.zeros(probs.shape)\n",
    "# predictions[np.where(probs >= 0.5)] = 1\n",
    "\n",
    "# predicted_labels = [ans_cols[myIndex] for myIndex, label in enumerate(predictions) if label == 1.0]\n",
    "# print(predicted_labels)\n",
    "\n",
    "print(model(tryInput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
